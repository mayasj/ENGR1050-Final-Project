# -*- coding: utf-8 -*-
"""Logistic Regression Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C2xx04aZCF54ajCkna1yDMwWtvUAA9NI
"""

import os             # Good for navigating your computer's files
import numpy as np    # Great for lists (arrays) of numbers
import pandas as pd   # Great for tables (google spreadsheets, microsoft excel, csv)
from sklearn.metrics import accuracy_score   # Great for creating quick ML models
#from google.colab import drive #COMMENT OUT IF USING GRADESCOPE
#drive.mount('/content/drive') #COMMENT OUT IF USING GRADESCOPE
from sklearn.model_selection import train_test_split


data_path  = '/content/drive/MyDrive/Dataset/Excel1.xlsx'

dataframe = pd.read_excel(data_path)

dataframe = dataframe[['diagnosis', 'x.perimeter_mean', 'x.radius_mean', 'x.texture_mean', 'x.area_mean', 'x.smoothness_mean', 'x.concavity_mean', 'x.symmetry_mean']]
dataframe['diagnosis_cat'] = dataframe['diagnosis'].astype('category').map({1: '1 (malignant)', 0: '0 (benign)'})

dataframe.head(5)

dataframe.info()

import seaborn as sns
import matplotlib.pyplot as plt

sns.catplot(x = 'x.concavity_mean', y = 'diagnosis_cat', data = dataframe, order=['1 (malignant)', '0 (benign)'])
dataframe.head()

from sklearn import linear_model

X,y = dataframe[['x.radius_mean']], dataframe[['diagnosis']]

model = linear_model.LinearRegression()
model.fit(X, y)
preds = model.predict(X)

sns.scatterplot(x='x.radius_mean', y='diagnosis', data=dataframe)
plt.plot(X, preds, color='r')
plt.legend(['Linear Regression Fit', 'Data'])

boundary = 15 # chosen value, can change!

sns.catplot(x = 'x.radius_mean', y = 'diagnosis_cat', data = dataframe, order=['1 (malignant)', '0 (benign)'])
plt.plot([boundary, boundary], [-.2, 1.2], 'g', linewidth = 2)

def boundary_classifier(target_boundary, radius_mean_series):
  result = [] #fill this in with predictions!

  for radius_mean in radius_mean_series:
    if radius_mean >= target_boundary:
      result.append(1)
    else:
      result.append(0)
  return result

chosen_boundary = 0.08    #chosen value, can change!

y_pred = boundary_classifier(chosen_boundary, dataframe['x.concavity_mean'])
dataframe['predicted'] = y_pred

y_true = dataframe['diagnosis']

sns.catplot(x = 'x.concavity_mean', y = 'diagnosis_cat', hue = 'predicted', data = dataframe, order=['1 (malignant)', '0 (benign)'])
plt.plot([chosen_boundary, chosen_boundary], [-.2, 1.2], 'g', linewidth = 2)

from sklearn.model_selection import train_test_split

train_df, test_df = train_test_split(dataframe, test_size = 0.2, random_state = 1)

logreg_model = linear_model.LogisticRegression()

X_train = train_df[X]
y_train = train_df[y]

logreg_model.fit(X_train, y_train)

X_test = test_df[X]
y_test = test_df[y]

y_pred = logreg_model.predict(X_test)

test_df['predicted'] = y_pred.squeeze()
sns.catplot(x = X[0], y = 'diagnosis_cat', hue = 'predicted', data=test_df, order=['1 (malignant)', '0 (benign)'])

accuracy = accuracy_score(y_test, y_pred)   # find and print the accuracy
print("The model's accuracy is", accuracy)

# Import the metrics class
from sklearn import metrics

# Create the Confusion Matrix
# y_test = dataframe['diagnosis']
cnf_matrix = metrics.confusion_matrix(y_test, y_pred)

# Visualizing the Confusion Matrix
class_names = [0,1] # Our diagnosis categories

fig, ax = plt.subplots()
# Setting up and visualizing the plot (do not worry about the code below!)
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g') # Creating heatmap
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix', y = 1.1)
plt.ylabel('Actual diagnosis')
plt.xlabel('Predicted diagnosis')
